"""Tests for configuration dataclasses."""

import json
import tempfile
from pathlib import Path
from unittest.mock import patch

import pytest

from puppeteer.config import (
    Config,
    CpuPlayer,
    PilotPlayer,
    PotatoPlayer,
    _generate_player_name,
    _resolve_personality,
    _resolve_preset,
    _resolve_randoms,
    _validate_name_parts,
    load_models,
    load_personalities,
    load_presets,
    load_prompts,
    load_toolsets,
)


def test_config_defaults():
    config = Config()
    assert config.server == "localhost"
    assert config.start_port == 17171
    assert config.potato_players == []
    assert config.pilot_players == []


def test_config_load_players_from_json():
    config_data = {
        "players": [
            {"type": "potato", "name": "spud"},
            {"type": "cpu", "name": "skynet"},
            {"type": "pilot", "name": "ace", "preset": "test-preset"},
        ],
        "matchTimeLimit": "MIN__60",
        "gameType": "Two Player Duel",
    }

    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)

        # Create presets + prompts so preset resolution works
        presets = {
            "presets": {"test-preset": {"model": "test/model", "system_prompt": "default"}},
            "random_pool": [],
        }
        (tmpdir_path / "presets.json").write_text(json.dumps(presets))
        (tmpdir_path / "prompts.json").write_text(json.dumps({"default": "You are a test player."}))
        (tmpdir_path / "personalities.json").write_text("{}")
        (tmpdir_path / "models.json").write_text('{"models": []}')

        config_path = tmpdir_path / "config.json"
        config_path.write_text(json.dumps(config_data))

        config = Config(config_file=config_path)
        config.load_config()

        assert len(config.potato_players) == 1
        assert config.potato_players[0].name == "spud"
        assert len(config.cpu_players) == 1
        assert isinstance(config.cpu_players[0], CpuPlayer)
        assert len(config.pilot_players) == 1
        assert isinstance(config.pilot_players[0], PilotPlayer)
        assert config.pilot_players[0].model == "test/model"
        assert config.match_time_limit == "MIN__60"
        assert config.game_type == "Two Player Duel"


def test_player_dataclass_fields():
    player = PotatoPlayer(name="test")
    assert player.name == "test"
    assert player.deck is None

    player_with_deck = PotatoPlayer(name="test", deck="decks/test.dck")
    assert player_with_deck.deck == "decks/test.dck"


def test_get_players_config_json_roundtrip():
    """Load players from JSON, serialize back, verify structure is preserved."""
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)

        presets = {
            "presets": {"test-preset": {"model": "test/model", "system_prompt": "default"}},
            "random_pool": [],
        }
        (tmpdir_path / "presets.json").write_text(json.dumps(presets))
        (tmpdir_path / "prompts.json").write_text(json.dumps({"default": "Test prompt."}))
        (tmpdir_path / "personalities.json").write_text("{}")
        (tmpdir_path / "models.json").write_text('{"models": []}')

        config_data = {
            "players": [
                {"type": "potato", "name": "spud", "deck": "decks/burn.dck"},
                {"type": "pilot", "name": "ace", "preset": "test-preset", "deck": "decks/control.dck"},
                {"type": "cpu", "name": "skynet"},
            ],
            "gameType": "Two Player Duel",
            "deckType": "Constructed - Legacy",
        }

        config_path = tmpdir_path / "config.json"
        config_path.write_text(json.dumps(config_data))

        config = Config(config_file=config_path)
        config.load_config()
        result = json.loads(config.get_players_config_json())

        assert result["gameType"] == "Two Player Duel"
        assert result["deckType"] == "Constructed - Legacy"
        names = [p["name"] for p in result["players"]]
        assert "spud" in names
        assert "ace" in names
        assert "skynet" in names


def test_get_players_config_json_empty():
    """No players should return empty string."""
    config = Config()
    assert config.get_players_config_json() == ""


def test_legacy_skeleton_treated_as_potato():
    """Skeleton player type should be loaded as a PotatoPlayer."""
    config_data = {
        "players": [
            {"type": "skeleton", "name": "bones"},
        ],
    }

    with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
        json.dump(config_data, f)
        config_path = Path(f.name)

    try:
        config = Config(config_file=config_path)
        config.load_config()
        assert len(config.potato_players) == 1
        assert config.potato_players[0].name == "bones"
        assert isinstance(config.potato_players[0], PotatoPlayer)
    finally:
        config_path.unlink()


def test_config_default_player_name():
    """Players without a name should get 'player-{index}' as default."""
    config_data = {
        "players": [
            {"type": "potato"},
            {"type": "cpu"},
        ],
    }

    with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
        json.dump(config_data, f)
        config_path = Path(f.name)

    try:
        config = Config(config_file=config_path)
        config.load_config()
        assert config.potato_players[0].name == "player-0"
        assert config.cpu_players[0].name == "player-1"
    finally:
        config_path.unlink()


def test_run_tag_no_config_file_raises():
    config = Config()
    with pytest.raises(AssertionError, match="run_tag requires config_file"):
        _ = config.run_tag


def test_run_tag_dumb():
    config = Config(config_file=Path("configs/dumb.json"))
    assert config.run_tag == "dumb"


def test_run_tag_gauntlet():
    config = Config(config_file=Path("configs/gauntlet.json"))
    assert config.run_tag == "gauntlet"


def test_run_tag_frontier():
    config = Config(config_file=Path("configs/frontier.json"))
    assert config.run_tag == "frontier"


def test_run_tag_llm4():
    config = Config(config_file=Path("configs/llm4.json"))
    assert config.run_tag == "llm4"


def test_run_tag_legacy_dumb():
    config = Config(config_file=Path("configs/legacy-dumb.json"))
    assert config.run_tag == "legacy-dumb"


def test_run_tag_custom():
    config = Config(config_file=Path("custom-thing.json"))
    assert config.run_tag == "custom-thing"


# --- Preset tests ---

SAMPLE_PRESETS = {
    "presets": {
        "fast-medium": {"model": "test/model-a", "reasoning_effort": "medium", "system_prompt": "default"},
        "slow-high": {"model": "test/model-b", "reasoning_effort": "high", "system_prompt": "default"},
        "bare": {"model": "test/model-c", "system_prompt": "default"},
    },
    "random_pool": ["fast-medium", "slow-high"],
}

SAMPLE_PROMPTS: dict[str, str] = {
    "default": "You are a test player.",
}


def test_preset_resolves_model_and_effort():
    """Preset should set model and reasoning_effort on player."""
    player = PilotPlayer(name="test", preset="fast-medium")
    _resolve_preset(player, SAMPLE_PRESETS, SAMPLE_PROMPTS)
    assert player.model == "test/model-a"
    assert player.reasoning_effort == "medium"
    assert player.system_prompt == "You are a test player."


def test_preset_without_reasoning_effort():
    """Preset without reasoning_effort should leave it None."""
    player = PilotPlayer(name="test", preset="bare")
    _resolve_preset(player, SAMPLE_PRESETS, SAMPLE_PROMPTS)
    assert player.model == "test/model-c"
    assert player.reasoning_effort is None


def test_preset_unknown_raises():
    """Unknown preset name should raise ValueError."""
    player = PilotPlayer(name="test", preset="nonexistent")
    with pytest.raises(ValueError, match="Unknown preset"):
        _resolve_preset(player, SAMPLE_PRESETS, SAMPLE_PROMPTS)


def test_preset_unknown_prompt_raises():
    """Preset referencing unknown prompt key should raise ValueError."""
    presets = {"presets": {"bad": {"model": "test/m", "system_prompt": "missing"}}, "random_pool": []}
    player = PilotPlayer(name="test", preset="bad")
    with pytest.raises(ValueError, match="unknown prompt"):
        _resolve_preset(player, presets, SAMPLE_PROMPTS)


def test_preset_no_preset_is_noop():
    """Player without preset should not be modified."""
    player = PilotPlayer(name="test")
    _resolve_preset(player, SAMPLE_PRESETS, SAMPLE_PROMPTS)
    assert player.model is None
    assert player.reasoning_effort is None


# --- Personality tests ---

SAMPLE_PERSONALITIES = {
    "test-pal": {
        "name_part": "Pal",
        "prompt_suffix": "You are very friendly.",
    },
    "test-villain": {
        "name_part": "Villain",
        "prompt_suffix": "You are evil.",
    },
}


def test_personality_sets_prompt_suffix():
    """Personality should set prompt_suffix on player."""
    player = PilotPlayer(name="TestName", model="test/model-a")
    player.personality = "test-pal"
    _resolve_personality(player, SAMPLE_PERSONALITIES, {}, had_explicit_name=True)
    assert player.prompt_suffix == "You are very friendly."


def test_personality_does_not_set_model():
    """Personality should NOT set model (that's the preset's job)."""
    player = PilotPlayer(name="TestName")
    player.personality = "test-pal"
    _resolve_personality(player, SAMPLE_PERSONALITIES, {}, had_explicit_name=True)
    assert player.model is None


def test_personality_unknown_raises():
    """Unknown personality name should raise ValueError."""
    player = PilotPlayer(name="test")
    player.personality = "nonexistent"
    with pytest.raises(ValueError, match="Unknown personality"):
        _resolve_personality(player, SAMPLE_PERSONALITIES, {}, had_explicit_name=True)


def test_personality_explicit_name_preserved():
    """Explicit name in player JSON should be kept."""
    player = PilotPlayer(name="CustomName", model="test/model-a")
    player.personality = "test-pal"
    _resolve_personality(player, SAMPLE_PERSONALITIES, {}, had_explicit_name=True)
    assert player.name == "CustomName"


def test_personality_name_too_long_raises():
    """Name exceeding 14 chars should raise ValueError."""
    player = PilotPlayer(name="ThisNameIsTooLong")
    player.personality = "test-pal"
    with pytest.raises(ValueError, match="3-14 characters"):
        _resolve_personality(player, SAMPLE_PERSONALITIES, {}, had_explicit_name=True)


def test_load_personalities_from_file():
    """load_personalities should read a JSON file."""
    pdata = {"my-pal": {"name_part": "Pal", "prompt_suffix": "hi"}}
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)
        (tmpdir_path / "personalities.json").write_text(json.dumps(pdata))
        config_path = tmpdir_path / "test-config.json"
        config_path.write_text("{}")

        result = load_personalities(config_path)
        assert "my-pal" in result
        assert result["my-pal"]["name_part"] == "Pal"


def test_load_presets_from_file():
    """load_presets should read a JSON file."""
    pdata = {"presets": {"x": {"model": "test/m", "system_prompt": "default"}}, "random_pool": []}
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)
        (tmpdir_path / "presets.json").write_text(json.dumps(pdata))
        config_path = tmpdir_path / "test-config.json"
        config_path.write_text("{}")

        result = load_presets(config_path)
        assert "presets" in result
        assert "x" in result["presets"]


def test_load_prompts_from_file():
    """load_prompts should read a JSON file."""
    pdata = {"default": "Hello world"}
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)
        (tmpdir_path / "prompts.json").write_text(json.dumps(pdata))
        config_path = tmpdir_path / "test-config.json"
        config_path.write_text("{}")

        result = load_prompts(config_path)
        assert result["default"] == "Hello world"


def test_preset_end_to_end_config_load():
    """Full integration: config JSON with preset+personality loads correctly."""
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)

        personalities = {
            "test-hero": {
                "name_part": "Hero",
                "prompt_suffix": "You are heroic.",
            }
        }
        (tmpdir_path / "personalities.json").write_text(json.dumps(personalities))

        presets = {
            "presets": {
                "test-preset": {"model": "test/hero-model", "reasoning_effort": "medium", "system_prompt": "default"},
            },
            "random_pool": [],
        }
        (tmpdir_path / "presets.json").write_text(json.dumps(presets))
        (tmpdir_path / "prompts.json").write_text(json.dumps({"default": "Be a great player."}))
        (tmpdir_path / "models.json").write_text(
            json.dumps({"models": [{"id": "test/hero-model", "name": "Hero Model", "name_part": "HeroM"}]})
        )

        config_data = {
            "players": [
                {"type": "pilot", "preset": "test-preset", "personality": "test-hero", "deck": "random"},
                {
                    "type": "pilot",
                    "name": "Override",
                    "preset": "test-preset",
                    "personality": "test-hero",
                    "deck": "random",
                },
            ]
        }
        config_path = tmpdir_path / "config.json"
        config_path.write_text(json.dumps(config_data))

        config = Config(config_file=config_path)
        config.load_config()

        assert len(config.pilot_players) == 2

        # First player: model from preset, prompt_suffix from personality, name generated
        p1 = config.pilot_players[0]
        assert p1.model == "test/hero-model"
        assert p1.prompt_suffix == "You are heroic."
        assert p1.reasoning_effort == "medium"
        assert p1.system_prompt == "Be a great player."
        assert p1.personality == "test-hero"
        assert p1.name == "HeroM Hero"

        # Second player: explicit name overrides generated name
        p2 = config.pilot_players[1]
        assert p2.name == "Override"
        assert p2.model == "test/hero-model"
        assert p2.prompt_suffix == "You are heroic."


# --- Random resolution tests ---

SAMPLE_MODELS_DATA = {
    "models": [
        {"id": "test/model-a", "name": "Model A", "name_part": "ModA"},
        {"id": "test/model-b", "name": "Model B", "name_part": "ModB"},
        {"id": "test/model-c", "name": "Model C", "name_part": "ModC"},
    ],
}

SAMPLE_PRESETS_WITH_POOL = {
    "presets": {
        "preset-a": {"model": "test/model-a", "reasoning_effort": "medium", "system_prompt": "default"},
        "preset-b": {"model": "test/model-b", "reasoning_effort": "high", "system_prompt": "default"},
        "preset-c": {"model": "test/model-c", "system_prompt": "default"},
    },
    "random_pool": ["preset-a", "preset-b", "preset-c"],
}

SAMPLE_PERSONALITIES_WITH_PARTS = {
    "hero": {
        "name_part": "Hero",
        "prompt_suffix": "You are heroic.",
    },
    "chill": {
        "name_part": "Chill",
        "prompt_suffix": "You are chill.",
    },
    "nerd": {
        "name_part": "Nerd",
        "prompt_suffix": "You are nerdy.",
    },
}


def test_validate_name_parts_valid():
    """Valid name_part combos should not raise."""
    _validate_name_parts(SAMPLE_PERSONALITIES_WITH_PARTS, SAMPLE_PRESETS_WITH_POOL, SAMPLE_MODELS_DATA)


def test_validate_name_parts_catches_overflow():
    """name_part combo > 14 chars should raise ValueError."""
    bad_personalities = {
        "longname": {"name_part": "TooLong!", "prompt_suffix": "hi"},
    }
    bad_presets = {
        "presets": {"p": {"model": "test/m", "system_prompt": "default"}},
        "random_pool": ["p"],
    }
    bad_models = {
        "models": [{"id": "test/m", "name": "M", "name_part": "Longish"}],
    }
    # "Longish TooLong!" = 16 chars
    with pytest.raises(ValueError, match="Invalid name_part combinations"):
        _validate_name_parts(bad_personalities, bad_presets, bad_models)


def test_validate_name_parts_missing_preset_in_pool():
    """random_pool preset not in presets should raise."""
    bad_presets = {
        "presets": {},
        "random_pool": ["missing"],
    }
    with pytest.raises(ValueError, match="not found in presets"):
        _validate_name_parts(SAMPLE_PERSONALITIES_WITH_PARTS, bad_presets, SAMPLE_MODELS_DATA)


def test_validate_name_parts_real_data():
    """Validate actual personalities.json x presets.json x models.json name_part combos all fit."""
    personalities = load_personalities(None)
    presets_data = load_presets(None)
    models_data = load_models(None)
    if not personalities or not presets_data or not models_data:
        pytest.skip("personalities.json, presets.json, or models.json not found")
    # Should not raise â€” if it does, we have a real misconfiguration
    _validate_name_parts(personalities, presets_data, models_data)


def test_generate_player_name():
    """Name should be '{model_part} {personality_part}'."""
    name = _generate_player_name("test/model-a", "hero", SAMPLE_MODELS_DATA, SAMPLE_PERSONALITIES_WITH_PARTS)
    assert name == "ModA Hero"


def test_generate_player_name_fallback():
    """Unknown model/personality should use fallback name_parts."""
    name = _generate_player_name("unknown/model", "unknown", SAMPLE_MODELS_DATA, SAMPLE_PERSONALITIES_WITH_PARTS)
    # Falls back to last part of model ID and personality key
    assert name == "model unknown"


def test_resolve_randoms_picks_personality_and_preset():
    """Random resolution should pick concrete personality and preset."""
    player = PilotPlayer(name="player-0", personality="random", preset="random")
    players = [(player, False)]

    with patch("puppeteer.config.random.choice", side_effect=["hero", "preset-b"]):
        _resolve_randoms(
            players, SAMPLE_PERSONALITIES_WITH_PARTS, SAMPLE_PRESETS_WITH_POOL, SAMPLE_PROMPTS, SAMPLE_MODELS_DATA
        )

    assert player.personality == "hero"
    assert player.preset == "preset-b"
    assert player.model == "test/model-b"
    assert player.prompt_suffix == "You are heroic."
    assert player.name == "ModB Hero"


def test_resolve_randoms_no_duplicate_personalities():
    """Multiple random players should get different personalities."""
    p1 = PilotPlayer(name="p0", personality="random", preset="random")
    p2 = PilotPlayer(name="p1", personality="random", preset="random")
    players = [(p1, False), (p2, False)]

    choices = ["hero", "preset-a", "chill", "preset-b"]
    with patch("puppeteer.config.random.choice", side_effect=choices):
        _resolve_randoms(
            players, SAMPLE_PERSONALITIES_WITH_PARTS, SAMPLE_PRESETS_WITH_POOL, SAMPLE_PROMPTS, SAMPLE_MODELS_DATA
        )

    assert p1.personality != p2.personality
    assert p1.preset != p2.preset


def test_resolve_randoms_explicit_preset_not_randomized():
    """Explicit preset should not be replaced by random."""
    player = PilotPlayer(name="player-0", personality="random", preset="preset-c")
    players = [(player, False)]

    with patch("puppeteer.config.random.choice", return_value="nerd"):
        _resolve_randoms(
            players, SAMPLE_PERSONALITIES_WITH_PARTS, SAMPLE_PRESETS_WITH_POOL, SAMPLE_PROMPTS, SAMPLE_MODELS_DATA
        )

    assert player.preset == "preset-c"
    assert player.model == "test/model-c"
    assert player.personality == "nerd"
    assert player.name == "ModC Nerd"


def test_resolve_randoms_explicit_name_preserved():
    """Explicit name in config should not be overwritten."""
    player = PilotPlayer(name="MyCustom", personality="random", preset="random")
    players = [(player, True)]  # had_explicit_name=True

    with patch("puppeteer.config.random.choice", side_effect=["hero", "preset-a"]):
        _resolve_randoms(
            players, SAMPLE_PERSONALITIES_WITH_PARTS, SAMPLE_PRESETS_WITH_POOL, SAMPLE_PROMPTS, SAMPLE_MODELS_DATA
        )

    assert player.name == "MyCustom"


def test_resolve_randoms_non_random_untouched():
    """Players with non-random personality/preset should pass through normally."""
    player = PilotPlayer(name="player-0", personality="hero", preset="preset-a")
    players = [(player, False)]

    _resolve_randoms(
        players, SAMPLE_PERSONALITIES_WITH_PARTS, SAMPLE_PRESETS_WITH_POOL, SAMPLE_PROMPTS, SAMPLE_MODELS_DATA
    )

    assert player.personality == "hero"
    assert player.preset == "preset-a"
    assert player.model == "test/model-a"
    assert player.name == "ModA Hero"  # Generated from model + personality


def test_random_end_to_end_config_load():
    """Full integration: config with random values resolves to concrete players."""
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)

        personalities = {
            "alpha": {
                "name_part": "Alpha",
                "prompt_suffix": "You are alpha.",
            },
            "beta": {
                "name_part": "Beta",
                "prompt_suffix": "You are beta.",
            },
        }
        (tmpdir_path / "personalities.json").write_text(json.dumps(personalities))

        presets = {
            "presets": {
                "fast-med": {"model": "test/fast", "reasoning_effort": "medium", "system_prompt": "default"},
                "smart-med": {"model": "test/smart", "reasoning_effort": "medium", "system_prompt": "default"},
            },
            "random_pool": ["fast-med", "smart-med"],
        }
        (tmpdir_path / "presets.json").write_text(json.dumps(presets))
        (tmpdir_path / "prompts.json").write_text(json.dumps({"default": "Test prompt."}))

        models = {
            "models": [
                {"id": "test/fast", "name": "Fast", "name_part": "Fast"},
                {"id": "test/smart", "name": "Smart", "name_part": "Smart"},
            ],
        }
        (tmpdir_path / "models.json").write_text(json.dumps(models))

        config_data = {
            "matchTimeLimit": "MIN__60",
            "players": [
                {"type": "pilot", "preset": "random", "personality": "random", "deck": "random"},
                {"type": "pilot", "preset": "random", "personality": "random", "deck": "random"},
            ],
        }
        config_path = tmpdir_path / "config.json"
        config_path.write_text(json.dumps(config_data))

        with patch("puppeteer.config.random.choice", side_effect=["alpha", "fast-med", "beta", "smart-med"]):
            config = Config(config_file=config_path)
            config.load_config()

        assert len(config.pilot_players) == 2
        p1, p2 = config.pilot_players

        assert p1.personality == "alpha"
        assert p1.preset == "fast-med"
        assert p1.model == "test/fast"
        assert p1.name == "Fast Alpha"
        assert p1.prompt_suffix == "You are alpha."

        assert p2.personality == "beta"
        assert p2.preset == "smart-med"
        assert p2.model == "test/smart"
        assert p2.name == "Smart Beta"
        assert p2.prompt_suffix == "You are beta."


# --- Format-aware random deck selection tests ---


def test_resolve_random_decks_legacy_format():
    """With deckType='Constructed - Legacy', decks should come from Legacy dir."""
    with tempfile.TemporaryDirectory() as tmpdir:
        root = Path(tmpdir)
        legacy_dir = root / "Mage.Client" / "release" / "sample-decks" / "Legacy"
        legacy_dir.mkdir(parents=True)
        (legacy_dir / "Burn.dck").write_text("4 [M21:1] Lightning Bolt\n")
        (legacy_dir / "Delver.dck").write_text("4 [ISD:1] Delver of Secrets\n")

        config = Config(deck_type="Constructed - Legacy")
        config.cpu_players = [CpuPlayer(name="cpu1", deck="random")]
        config.resolve_random_decks(root)

        assert config.cpu_players[0].deck is not None
        assert "Legacy" in config.cpu_players[0].deck
        assert config.cpu_players[0].deck.endswith(".dck")


def test_resolve_random_decks_modern_format():
    """With deckType='Constructed - Modern', decks should come from Modern dir."""
    with tempfile.TemporaryDirectory() as tmpdir:
        root = Path(tmpdir)
        modern_dir = root / "Mage.Client" / "release" / "sample-decks" / "Modern"
        modern_dir.mkdir(parents=True)
        (modern_dir / "Burn.dck").write_text("4 [M21:1] Lightning Bolt\n")

        config = Config(deck_type="Constructed - Modern")
        config.cpu_players = [CpuPlayer(name="cpu1", deck="random")]
        config.resolve_random_decks(root)

        assert "Modern" in config.cpu_players[0].deck


def test_resolve_random_decks_default_commander():
    """Empty deckType should fall back to Commander directory."""
    with tempfile.TemporaryDirectory() as tmpdir:
        root = Path(tmpdir)
        commander_dir = root / "Mage.Client" / "release" / "sample-decks" / "Commander"
        commander_dir.mkdir(parents=True)
        (commander_dir / "Precon.dck").write_text("1 [CMD:1] Sol Ring\n")

        config = Config()
        config.cpu_players = [CpuPlayer(name="cpu1", deck="random")]
        config.resolve_random_decks(root)

        assert "Commander" in config.cpu_players[0].deck


def test_resolve_random_decks_no_duplicate_decks():
    """Two players with random decks should get different decks."""
    with tempfile.TemporaryDirectory() as tmpdir:
        root = Path(tmpdir)
        legacy_dir = root / "Mage.Client" / "release" / "sample-decks" / "Legacy"
        legacy_dir.mkdir(parents=True)
        (legacy_dir / "DeckA.dck").write_text("4 [M21:1] Card A\n")
        (legacy_dir / "DeckB.dck").write_text("4 [M21:2] Card B\n")
        (legacy_dir / "DeckC.dck").write_text("4 [M21:3] Card C\n")

        config = Config(deck_type="Constructed - Legacy")
        config.cpu_players = [
            CpuPlayer(name="cpu1", deck="random"),
            CpuPlayer(name="cpu2", deck="random"),
        ]
        config.resolve_random_decks(root)

        assert config.cpu_players[0].deck != config.cpu_players[1].deck


# --- Toolset tests ---

SAMPLE_TOOLSETS = {
    "default": ["pass_priority", "get_action_choices", "choose_action", "get_game_state"],
    "minimal": ["pass_priority", "choose_action"],
}


def test_load_toolsets_from_file():
    """load_toolsets should read a JSON file."""
    tdata = {"basic": ["pass_priority", "choose_action"]}
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)
        (tmpdir_path / "toolsets.json").write_text(json.dumps(tdata))
        config_path = tmpdir_path / "test-config.json"
        config_path.write_text("{}")

        result = load_toolsets(config_path)
        assert "basic" in result
        assert result["basic"] == ["pass_priority", "choose_action"]


def test_preset_resolves_toolset():
    """Preset with toolset should set tools on player."""
    presets = {
        "presets": {
            "with-tools": {
                "model": "test/model",
                "system_prompt": "default",
                "toolset": "minimal",
            }
        },
        "random_pool": [],
    }
    player = PilotPlayer(name="test", preset="with-tools")
    _resolve_preset(player, presets, SAMPLE_PROMPTS, SAMPLE_TOOLSETS)
    assert player.tools == ["pass_priority", "choose_action"]


def test_preset_without_toolset_leaves_none():
    """Preset without toolset key should leave tools as None."""
    player = PilotPlayer(name="test", preset="fast-medium")
    _resolve_preset(player, SAMPLE_PRESETS, SAMPLE_PROMPTS, SAMPLE_TOOLSETS)
    assert player.tools is None


def test_player_tools_override_preset_toolset():
    """Player-level tools should win over preset toolset."""
    presets = {
        "presets": {
            "with-tools": {
                "model": "test/model",
                "system_prompt": "default",
                "toolset": "default",
            }
        },
        "random_pool": [],
    }
    player = PilotPlayer(
        name="test",
        preset="with-tools",
        tools=["pass_priority", "get_game_state"],
    )
    _resolve_preset(player, presets, SAMPLE_PROMPTS, SAMPLE_TOOLSETS)
    # Player-level tools should win
    assert player.tools == ["pass_priority", "get_game_state"]


def test_preset_unknown_toolset_raises():
    """Preset referencing unknown toolset should raise ValueError."""
    presets = {
        "presets": {"bad": {"model": "test/m", "system_prompt": "default", "toolset": "nonexistent"}},
        "random_pool": [],
    }
    player = PilotPlayer(name="test", preset="bad")
    with pytest.raises(ValueError, match="unknown toolset"):
        _resolve_preset(player, presets, SAMPLE_PROMPTS, SAMPLE_TOOLSETS)


def test_tools_loaded_from_config_json():
    """tools field in player JSON should populate PilotPlayer.tools."""
    config_data = {
        "players": [
            {
                "type": "pilot",
                "name": "custom",
                "preset": "test-preset",
                "tools": ["pass_priority", "get_game_state"],
            },
        ],
    }
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)
        presets = {
            "presets": {"test-preset": {"model": "test/m", "system_prompt": "default"}},
            "random_pool": [],
        }
        (tmpdir_path / "presets.json").write_text(json.dumps(presets))
        (tmpdir_path / "prompts.json").write_text(json.dumps({"default": "Test."}))
        (tmpdir_path / "personalities.json").write_text("{}")
        (tmpdir_path / "models.json").write_text('{"models": []}')
        (tmpdir_path / "toolsets.json").write_text("{}")

        config_path = tmpdir_path / "config.json"
        config_path.write_text(json.dumps(config_data))

        config = Config(config_file=config_path)
        config.load_config()

        assert config.pilot_players[0].tools == ["pass_priority", "get_game_state"]


def test_tools_none_when_not_specified():
    """Player without tools should have tools=None when preset has no toolset."""
    config_data = {
        "players": [
            {"type": "pilot", "name": "plain", "preset": "test-preset"},
        ],
    }
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)
        presets = {
            "presets": {"test-preset": {"model": "test/m", "system_prompt": "default"}},
            "random_pool": [],
        }
        (tmpdir_path / "presets.json").write_text(json.dumps(presets))
        (tmpdir_path / "prompts.json").write_text(json.dumps({"default": "Test."}))
        (tmpdir_path / "personalities.json").write_text("{}")
        (tmpdir_path / "models.json").write_text('{"models": []}')
        (tmpdir_path / "toolsets.json").write_text("{}")

        config_path = tmpdir_path / "config.json"
        config_path.write_text(json.dumps(config_data))

        config = Config(config_file=config_path)
        config.load_config()

        assert config.pilot_players[0].tools is None


def test_toolset_end_to_end_config_load():
    """Full integration: config with preset referencing toolset resolves correctly."""
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)

        personalities = {"test-hero": {"name_part": "Hero", "prompt_suffix": "You are heroic."}}
        (tmpdir_path / "personalities.json").write_text(json.dumps(personalities))

        presets = {
            "presets": {
                "test-preset": {
                    "model": "test/hero-model",
                    "reasoning_effort": "medium",
                    "system_prompt": "default",
                    "toolset": "minimal",
                },
            },
            "random_pool": [],
        }
        (tmpdir_path / "presets.json").write_text(json.dumps(presets))
        (tmpdir_path / "prompts.json").write_text(json.dumps({"default": "Be great."}))
        (tmpdir_path / "models.json").write_text(
            json.dumps({"models": [{"id": "test/hero-model", "name": "Hero", "name_part": "HeroM"}]})
        )
        (tmpdir_path / "toolsets.json").write_text(json.dumps({"minimal": ["pass_priority", "choose_action"]}))

        config_data = {
            "players": [
                {"type": "pilot", "preset": "test-preset", "personality": "test-hero"},
            ]
        }
        config_path = tmpdir_path / "config.json"
        config_path.write_text(json.dumps(config_data))

        config = Config(config_file=config_path)
        config.load_config()

        p = config.pilot_players[0]
        assert p.model == "test/hero-model"
        assert p.tools == ["pass_priority", "choose_action"]
        assert p.system_prompt == "Be great."
