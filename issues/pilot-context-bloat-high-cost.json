{
  "title": "Pilot context bloat causes extreme token costs ($33/game for Sonnet)",
  "description": "Sonnet 4.5 cost $33.45 for a single 12-turn Commander game (77% of total $43.26 game cost). Two compounding factors:\n\n1. Context grows unchecked to ~200 messages before trimming to ~162. With 3+ messages per action cycle (call + result + response), the window stays enormous. Prompt tokens grew from 4K to 23K per call (6.7x). Last 20 calls averaged 21,206 prompt tokens each.\n\n2. Sonnet made 769 LLM calls vs 432 for Haiku playing the same game. Tool distribution: 274 pass_priority (vs 127), 234 get_action_choices (vs 137). More calls x bigger context = cost explosion.\n\nTotal: 10.9M prompt tokens at ~$3/M = $33. Haiku had similar context growth (4Kâ†’23K) but fewer calls and cheaper per-token rate ($7.39 total).\n\nEvidence:\n- ~/mage-bench-logs/game_20260210_170138/Sonnet4.5_cost.json: $33.45\n- Sonnet4.5_llm.jsonl: 769 llm_response entries, 26 context_trim events\n- First 20 calls avg 4,089 prompt tokens, last 20 avg 21,206\n\nSource: puppeteer/src/puppeteer/pilot.py:430-476 (trim logic)\n\nSuggested fixes:\n- Reduce trim threshold from 200 to 100 messages, trim target from 160 to 60\n- Summarize old tool results (replace full JSON with one-line summary after LLM has responded)\n- Consider model-specific trim targets for expensive models\n- Drop full tool result content from history after N messages",
  "status": "open",
  "priority": 2,
  "type": "task",
  "labels": ["puppeteer", "pilot"],
  "created_at": "2026-02-10T18:30:00.000000-08:00",
  "updated_at": "2026-02-10T18:30:00.000000-08:00"
}
